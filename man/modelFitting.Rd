% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/modelFitting.r
\name{modelFitting}
\alias{modelFitting}
\title{fit a model minimizing the (symmetric) mean squared  distance}
\usage{
modelFitting(
  model,
  tarmesh,
  iterations = 5,
  lbfgs.iter = 5,
  lbfgs.orthantwise_c = 0,
  symmetric = c(0, 1, 2),
  refdist = 1e+05,
  tardist = 1e+05,
  rho = pi/2,
  sdmax = NULL,
  mahaprob = c("none", "chisq", "dist"),
  initparams = NULL,
  k = 50,
  threads = 0,
  method = "lbfgs",
  silent = FALSE,
  ...
)
}
\arguments{
\item{model}{statistical model of class pPCA}

\item{tarmesh}{a target mesh already aligned to the model}

\item{iterations}{numbers of iterations to run}

\item{lbfgs.iter}{integer:}

\item{lbfgs.orthantwise_c}{integer or integer vector of length iterations. Contains coefficient(x) for the \code{L1} norm of variables. This parameter should be set to zero for standard minimization
problems. Setting this parameter to a positive value
activates Orthant-Wise Limited-memory Quasi-Newton (OWL-QN)
method, which minimizes the objective function \code{F(x)}
combined with the L1 norm \code{|x|} of the variables, \code{{F(x) + C
|x|}}. This parameter is the coefficient for the \code{|x|}, i.e.,
\code{C}. As the L1 norm \code{|x|} is not differentiable at zero, the
library modifies function and gradient evaluations from a
client program suitably. The default value is zero. Note that
the objective function minimized by alternative packages
(e.g., \code{glmnet}) is of the form : \code{F(x)/N + C |x|}, where \code{N}
is the number of parameters. \code{lbfgs} does not divide the
likelihood function by \code{N}. To achieve equivalence with
\code{glmnet} result, take this difference of implementation into
account.}

\item{symmetric}{integer: specify which MSE to minimize. 0=search both ways, 1=model to target, 2=target to model.}

\item{refdist}{maximal distance from model to reference to be considered}

\item{tardist}{maximal distance from target to model to be considered}

\item{rho}{numeric: allowed normal deviation of a point to be considered as corresponding.}

\item{sdmax}{constrain parameters (normalized PC-scores) to be within +- sdmax}

\item{mahaprob}{character: if != "none", use mahalanobis-distance to determine overall probability (of the shape projected into the model space."chisq" uses the Chi-Square distribution of the squared Mahalanobisdistance, while "dist" restricts the values to be within a multi-dimensional sphere of radius \code{sdmax}. If FALSE the probability will be determined per PC separately.}

\item{initparams}{a vector with initial estimations of the model parameters. Set to zeros if NULL.}

\item{k}{integer: amount of closest faces to consider during closest point search.}

\item{threads}{integer: number of cores to use for closest point search}

\item{method}{optimizer method. Can be one of "lbfgs", "BFGS", "CG", "L-BFGS-B", "SANN", "Brent". lbfgs calls the function from package lbfgs, while the others call \code{\link{optim}}.}

\item{silent}{logical: if TRUE output will be suppressed.}

\item{...}{additional parameters to be passed to \code{\link{lbfgs}} or \code{\link{optim}}.}
}
\value{
\item{par}{the model's parameters}
\item{mesh}{the fitted mesh}
}
\description{
fit a model minimizing the (symmetric) mean squared distance
}
\details{
this function fits a statistical model to a target mesh using a l-bfgs optimizer to minimize the symmetric mean squared distance between meshes.
}
\note{
needs RvtkStatismo installed
}
\examples{
\dontrun{
require(RvtkStatismo)
download.file(url="https://github.com/marcelluethi/
statismo-shaperegistration/raw/master/data/VSD001_femur.vtk","./VSD001_femur.vtk",method = "w")
download.file(url="https://github.com/marcelluethi/
statismo-shaperegistration/raw/master/data/VSD002_femur.vtk","./VSD002_femur.vtk",method = "w")
download.file(url="https://github.com/marcelluethi/
statismo-shaperegistration/raw/master/data/VSD001-lm.csv","./VSD001-lm.csv",method = "w")
download.file(url="https://github.com/marcelluethi/
statismo-shaperegistration/raw/master/data/VSD002-lm.csv","./VSD002-lm.csv",method = "w")
ref <- read.vtk("VSD001_femur.vtk")
tar <- read.vtk("VSD002_femur.vtk")
ref.lm <- as.matrix(read.csv("VSD001-lm.csv",row.names=1,header = FALSE))
tar.lm <- as.matrix(read.csv("VSD002-lm.csv",row.names=1,header = FALSE))
Kernels <- SumKernels(GaussianKernel(50,50),IsoKernel(0.1,ref))
mymod <- statismoModelFromRepresenter(ref,kernel=Kernels)
mymodC <- RvtkStatismo::statismoConstrainModel(mymod,tar.lm,ref.lm,2)
fit <- modelFitting(mymodC,tar,iterations = 15)
#or without landmarks but instead with some icp steps
taricp <- icp(tar,ref,iterations = 50,type="s",getTransform = TRUE)
taricpAff <- icp(taricp$mesh,ref,iterations = 50,type="a",getTransform = TRUE)
##get affine transform
combotrafo <- taricpAff$transform\%*\%taricp$transform
fit2 <- modelFitting(mymod,taricpAff$mesh,iterations = 15)
## revert affine transforms
fit2aff <- applyTransform(fit2$mesh,combotrafo,inverse=TRUE)
}
}
